{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('air_visit_data.csv'),\n",
    "    'as': pd.read_csv('air_store_info.csv'),\n",
    "    'hs': pd.read_csv('hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('air_reserve.csv'),\n",
    "    'hr': pd.read_csv('hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('sample_submission.csv'),\n",
    "    'hol': pd.read_csv('date_info.csv').rename(columns={'calendar_date':'visit_date'}),\n",
    "    'before': pd.read_csv('before_42D_data.csv')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "data['hr'] = pd.merge(data['hr'], data['as'], how='left', on=['air_store_id'])\n",
    "data['ar'] = pd.merge(data['ar'], data['as'], how='left', on=['air_store_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing for reservation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_area = {}\n",
    "tmp_genre = {}\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['v_r_diff'] = data[df].apply(\n",
    "        lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp_area[df] = data[df].groupby(\n",
    "        ['air_area_name','visit_datetime'],as_index=False)['reserve_visitors'].median().rename(\n",
    "        columns={'visit_datetime':'visit_date','reserve_visitors':'area_reserve_visitors'})\n",
    "    tmp_genre[df] = data[df].groupby(\n",
    "        ['air_genre_name','visit_datetime'],as_index=False)['reserve_visitors'].median().rename(\n",
    "        columns={'visit_datetime':'visit_date','reserve_visitors':'genre_reserve_visitors'})\n",
    "    data[df] = data[df].groupby(\n",
    "        ['air_store_id','visit_datetime'], \n",
    "        as_index=False)['reserve_visitors'].sum().rename(columns={'visit_datetime':'visit_date'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['week'] = data['tra']['visit_date'].dt.week\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tes']['visit_date'] = data['tes']['id'].map(\n",
    "    lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(\n",
    "    lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['week'] = data['tes']['visit_date'].dt.week\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id','dow'],as_index=False)['visitors'].min().rename(columns={\n",
    "    'visitors':'min_visitors'})\n",
    "data['tra'] = pd.merge(data['tra'], tmp, how='left', on=['air_store_id','dow'])\n",
    "data['tes'] = pd.merge(data['tes'], tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id','dow'],as_index=False)['visitors'].max().rename(columns={\n",
    "    'visitors':'max_visitors'})\n",
    "data['tra'] = pd.merge(data['tra'], tmp, how='left', on=['air_store_id','dow'])\n",
    "data['tes'] = pd.merge(data['tes'], tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id','dow'],as_index=False)['visitors'].mean().rename(columns={\n",
    "    'visitors':'mean_visitors'})\n",
    "data['tra'] = pd.merge(data['tra'], tmp, how='left', on=['air_store_id','dow'])\n",
    "data['tes'] = pd.merge(data['tes'], tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id','dow'],as_index=False)['visitors'].median().rename(columns={\n",
    "    'visitors':'median_visitors'})\n",
    "data['tra'] = pd.merge(data['tra'], tmp, how='left', on=['air_store_id','dow'])\n",
    "data['tes'] = pd.merge(data['tes'], tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id','dow'],as_index=False)['visitors'].count().rename(columns={\n",
    "    'visitors':'count_visitors'})\n",
    "data['tra'] = pd.merge(data['tra'], tmp, how='left', on=['air_store_id','dow'])\n",
    "data['tes'] = pd.merge(data['tes'], tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['before']['visit_date'] = pd.to_datetime(data['before']['visit_date'])\n",
    "data['before']['visit_date'] = data['before']['visit_date'].dt.date\n",
    "data['tra'] = pd.merge(data['tra'], data['before'], how='left', on=['air_store_id','visit_date'])\n",
    "data['tes'] = pd.merge(data['tes'], data['before'], how='left', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra'] = pd.merge(data['tra'], data['as'], how='left', on=['air_store_id'])\n",
    "data['tes'] = pd.merge(data['tes'], data['as'], how='left', on=['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['hol']['day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra'] = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\n",
    "data['tes'] = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_r = pd.merge(data['ar'], data['hr'], \n",
    "                   how='outer', on=['air_store_id','visit_date']).fillna(0)\n",
    "train_r['reserve_visitor'] = train_r['reserve_visitors_x'] + train_r['reserve_visitors_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra'].dropna(inplace=True)\n",
    "data['tes'] = data['tes'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra'] = pd.merge(data['tra'], train_r, \n",
    "                       how='left', on=['air_store_id','visit_date']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tes'] = pd.merge(data['tes'], train_r, \n",
    "                       how='left', on=['air_store_id','visit_date']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_area = pd.merge(tmp_area['ar'], tmp_area['hr'], \n",
    "                    how='outer', on=['air_area_name','visit_date']).fillna(0)\n",
    "tmp_area['area_reserve_visitors'] = tmp_area['area_reserve_visitors_x'] + tmp_area['area_reserve_visitors_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp_area['area_reserve_visitors_x']\n",
    "del tmp_area['area_reserve_visitors_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_genre = pd.merge(tmp_genre['ar'], tmp_genre['hr'], \n",
    "                     how='outer', on=['air_genre_name','visit_date']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_genre['genre_reserve_visitors'] = tmp_genre['genre_reserve_visitors_x'] + tmp_genre['genre_reserve_visitors_y']\n",
    "del tmp_genre['genre_reserve_visitors_x']\n",
    "del tmp_genre['genre_reserve_visitors_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra'] = pd.merge(data['tra'], tmp_area, \n",
    "                       how='left', on=['visit_date','air_area_name']).fillna(0)\n",
    "data['tra'] = pd.merge(data['tra'], tmp_genre, \n",
    "                       how='left', on=['visit_date','air_genre_name']).fillna(0)\n",
    "data['tes'] = pd.merge(data['tes'], tmp_area, \n",
    "                       how='left', on=['visit_date','air_area_name']).fillna(0)\n",
    "data['tes'] = pd.merge(data['tes'], tmp_genre, \n",
    "                       how='left', on=['visit_date','air_genre_name']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_mapping = {label:idx+1 for idx,label in enumerate(np.unique(data['as']['air_genre_name']))}\n",
    "area_mapping = {label:idx+1 for idx,label in enumerate(np.unique(data['as']['air_area_name']))}\n",
    "\n",
    "#!!!!categorical varibales: family, class, cluster\n",
    "data['tra']['air_genre_name'] = data['tra']['air_genre_name'].map(genre_mapping)\n",
    "data['tra']['air_area_name'] = data['tra']['air_area_name'].map(area_mapping)\n",
    "data['tes']['air_genre_name'] = data['tes']['air_genre_name'].map(genre_mapping)\n",
    "data['tes']['air_area_name'] = data['tes']['air_area_name'].map(area_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = data['tra'].copy()\n",
    "test_all = data['tes'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_value = ['visitors','min_visitors','max_visitors',\n",
    "                'mean_visitors','median_visitors','count_visitors',\n",
    "                'before_mean_visit','before_min_visit','before_max_visit',\n",
    "                'before_median_visit','reserve_visitor','reserve_visitors_x',\n",
    "                'reserve_visitors_y','area_reserve_visitors','genre_reserve_visitors']\n",
    "\n",
    "for name in change_value:\n",
    "    train_all[name] = train_all[name].apply(lambda r:np.log1p(float(r)))\n",
    "    test_all[name] = test_all[name].apply(lambda r:np.log1p(float(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all['visit_date'] = pd.to_datetime(train_all['visit_date'])\n",
    "split_data = train_all[train_all['visit_date'] >= pd.to_datetime(date(2017,3,1))]\n",
    "train_part1 = train_all[train_all['visit_date'] < pd.to_datetime(date(2017,3,1))]\n",
    "train_part2, val = train_test_split(split_data, test_size=0.6)\n",
    "train = pd.concat([train_part1,train_part2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train['visitors'].values\n",
    "train_x = train.drop(['air_store_id','visit_date','visitors'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_y = val['visitors'].values\n",
    "val_x = val.drop(['air_store_id','visit_date','visitors'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 180,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.6,\n",
    "    'metric': 'l2_root',\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 8000\n",
    "cate_vars = ['air_genre_name','air_area_name',\n",
    "             'holiday_flg','dow', 'year', 'month','week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hetty/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/hetty/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 0.51053\tvalid_1's rmse: 0.509909\n",
      "[200]\ttraining's rmse: 0.494041\tvalid_1's rmse: 0.494398\n",
      "[300]\ttraining's rmse: 0.488027\tvalid_1's rmse: 0.490602\n",
      "[400]\ttraining's rmse: 0.484297\tvalid_1's rmse: 0.488602\n",
      "[500]\ttraining's rmse: 0.481565\tvalid_1's rmse: 0.487571\n",
      "[600]\ttraining's rmse: 0.479383\tvalid_1's rmse: 0.486912\n",
      "[700]\ttraining's rmse: 0.477343\tvalid_1's rmse: 0.486278\n",
      "[800]\ttraining's rmse: 0.475615\tvalid_1's rmse: 0.485602\n",
      "[900]\ttraining's rmse: 0.474018\tvalid_1's rmse: 0.485163\n",
      "[1000]\ttraining's rmse: 0.472481\tvalid_1's rmse: 0.484837\n",
      "[1100]\ttraining's rmse: 0.471032\tvalid_1's rmse: 0.484371\n",
      "[1200]\ttraining's rmse: 0.469684\tvalid_1's rmse: 0.483968\n",
      "[1300]\ttraining's rmse: 0.468383\tvalid_1's rmse: 0.483619\n",
      "[1400]\ttraining's rmse: 0.467101\tvalid_1's rmse: 0.483347\n",
      "[1500]\ttraining's rmse: 0.465849\tvalid_1's rmse: 0.483083\n",
      "[1600]\ttraining's rmse: 0.464632\tvalid_1's rmse: 0.482862\n",
      "[1700]\ttraining's rmse: 0.463461\tvalid_1's rmse: 0.48267\n",
      "[1800]\ttraining's rmse: 0.462313\tvalid_1's rmse: 0.482477\n",
      "[1900]\ttraining's rmse: 0.461221\tvalid_1's rmse: 0.482336\n",
      "[2000]\ttraining's rmse: 0.460067\tvalid_1's rmse: 0.482252\n",
      "[2100]\ttraining's rmse: 0.45904\tvalid_1's rmse: 0.48212\n",
      "[2200]\ttraining's rmse: 0.458\tvalid_1's rmse: 0.4819\n",
      "[2300]\ttraining's rmse: 0.456899\tvalid_1's rmse: 0.481739\n",
      "[2400]\ttraining's rmse: 0.455912\tvalid_1's rmse: 0.481613\n",
      "[2500]\ttraining's rmse: 0.454959\tvalid_1's rmse: 0.48152\n",
      "[2600]\ttraining's rmse: 0.453919\tvalid_1's rmse: 0.481403\n",
      "[2700]\ttraining's rmse: 0.452943\tvalid_1's rmse: 0.481304\n",
      "[2800]\ttraining's rmse: 0.451989\tvalid_1's rmse: 0.481184\n",
      "[2900]\ttraining's rmse: 0.451013\tvalid_1's rmse: 0.481085\n",
      "[3000]\ttraining's rmse: 0.450115\tvalid_1's rmse: 0.481027\n",
      "[3100]\ttraining's rmse: 0.449131\tvalid_1's rmse: 0.481002\n",
      "[3200]\ttraining's rmse: 0.448171\tvalid_1's rmse: 0.480942\n",
      "[3300]\ttraining's rmse: 0.447271\tvalid_1's rmse: 0.48093\n",
      "[3400]\ttraining's rmse: 0.446383\tvalid_1's rmse: 0.480889\n",
      "[3500]\ttraining's rmse: 0.445483\tvalid_1's rmse: 0.480836\n",
      "[3600]\ttraining's rmse: 0.444669\tvalid_1's rmse: 0.480774\n",
      "[3700]\ttraining's rmse: 0.443841\tvalid_1's rmse: 0.480755\n",
      "[3800]\ttraining's rmse: 0.443033\tvalid_1's rmse: 0.480751\n",
      "[3900]\ttraining's rmse: 0.442223\tvalid_1's rmse: 0.480722\n",
      "[4000]\ttraining's rmse: 0.441444\tvalid_1's rmse: 0.480712\n",
      "[4100]\ttraining's rmse: 0.440681\tvalid_1's rmse: 0.480714\n",
      "[4200]\ttraining's rmse: 0.439938\tvalid_1's rmse: 0.48072\n",
      "[4300]\ttraining's rmse: 0.439189\tvalid_1's rmse: 0.480718\n",
      "[4400]\ttraining's rmse: 0.438402\tvalid_1's rmse: 0.480673\n",
      "[4500]\ttraining's rmse: 0.437708\tvalid_1's rmse: 0.480697\n",
      "[4600]\ttraining's rmse: 0.436896\tvalid_1's rmse: 0.480684\n",
      "[4700]\ttraining's rmse: 0.436115\tvalid_1's rmse: 0.480697\n",
      "[4800]\ttraining's rmse: 0.435383\tvalid_1's rmse: 0.480695\n",
      "[4900]\ttraining's rmse: 0.434637\tvalid_1's rmse: 0.480698\n",
      "[5000]\ttraining's rmse: 0.433914\tvalid_1's rmse: 0.480716\n",
      "Early stopping, best iteration is:\n",
      "[4572]\ttraining's rmse: 0.43714\tvalid_1's rmse: 0.480668\n",
      "median_visitors: 1042800.58\n",
      "mean_visitors: 590611.83\n",
      "before_mean_visit: 117208.42\n",
      "before_median_visit: 88439.61\n",
      "min_visitors: 87612.74\n",
      "week: 84900.55\n",
      "air_area_name: 84481.10\n",
      "max_visitors: 46256.55\n",
      "reserve_visitor: 32546.39\n",
      "reserve_visitors_x: 25948.50\n",
      "dow: 16610.55\n",
      "month: 14954.85\n",
      "before_max_visit: 14494.70\n",
      "air_genre_name: 13684.98\n",
      "count_visitors: 11111.54\n",
      "holiday_flg: 8367.26\n",
      "before_min_visit: 6522.06\n",
      "genre_reserve_visitors: 5057.22\n",
      "longitude: 4125.42\n",
      "latitude: 3954.40\n",
      "area_reserve_visitors: 3779.58\n",
      "reserve_visitors_y: 2367.32\n",
      "year: 1877.18\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(\n",
    "    train_x, label=train_y,\n",
    "    categorical_feature=cate_vars)\n",
    "dval = lgb.Dataset(\n",
    "    val_x, label=val_y, reference=dtrain,\n",
    "    categorical_feature=cate_vars)\n",
    "\n",
    "bst = lgb.train(\n",
    "    params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "    valid_sets=[dtrain, dval], early_stopping_rounds=500,verbose_eval=100\n",
    ")\n",
    "\n",
    "print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "    zip(train_x, bst.feature_importance(\"gain\")),\n",
    "    key=lambda x: x[1], reverse=True\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_all.drop(['id','visitors','visit_date','air_store_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = bst.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all['visitors'] = np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all[['id','visitors']].to_csv('try14.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "267px",
    "left": "451px",
    "right": "20px",
    "top": "153px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
